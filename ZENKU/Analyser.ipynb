{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ba739e-b1e3-4824-bdb0-a7514253e664",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "644f0831-837a-43fe-ac53-378f0b8c08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnum = 8\n",
    "corr_all_Tsamples = []\n",
    "secret_range = 2**(bnum)\n",
    "M = round(secret_range / 2)\n",
    "hw = [hamming_weight(secret_value) for secret_value in range(secret_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f85d97a-f7a9-4942-9bdc-14343e391c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "mult_result = (256 * 10) % secret_range\n",
    "print(hw[mult_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e55c142-1a9f-4a66-b11d-f2c57bc0d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c8d4b9-d54e-4af5-9223-2050221e45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_weight(x, is_int = True):\n",
    "    if not is_int:\n",
    "        return np.count_nonzero(x == 1)\n",
    "    return bin(x).count(\"1\")\n",
    "def get_overflowed_val(val = 0, bnum = 8):\n",
    "    border = 2**(bnum-1)\n",
    "    if val >= border:\n",
    "        val = val % (border*2)\n",
    "        if val >= border:\n",
    "            val = -border + (val - border)\n",
    "    return val\n",
    "def V2_ANN_CPA_OTS(known_input : list, waves = np.array([]), n_traces = 300, trace_len = 24000, ith_weight = 0): # Vanilla ANN CPA, for one time_sample a\n",
    "    bnum = 8\n",
    "    corr_all_Tsamples = []\n",
    "    secret_range = 2**(bnum)\n",
    "    M = round(secret_range / 2)\n",
    "    hw = [hamming_weight(secret_value) for secret_value in range(secret_range)]\n",
    "\n",
    "    qsum_L_list = []\n",
    "    l_diff_list = []\n",
    "    for time_sample in range(trace_len):\n",
    "      L = waves[:,time_sample]\n",
    "      L_mean = np.mean(L, axis = 0)\n",
    "      qsum_L = 0\n",
    "      l_diff = [l - L_mean for l in L]\n",
    "      for w in range(M*2):\n",
    "        qsum_L += (l_diff[w])**2\n",
    "      qsum_L_list.append(qsum_L)\n",
    "      l_diff_list.append(l_diff)\n",
    "\n",
    "    # wave_Blen = round(len(waves[0]))\n",
    "    for secret_value in trange(secret_range, desc='Calculating Correlations for secret key'): # For current WeightHyphothesis do\n",
    "        corr_Tsamples = []\n",
    "        H = [] #Hyphotheticalleakage\n",
    "        for j in range(n_traces):  #  Get an array of possible HammingWeights for current WeightHyphothesis (for all the traces)\n",
    "            mult_result = (secret_value * known_input[j]) % secret_range\n",
    "            H.append(hw[mult_result])\n",
    "            #H.append(mult_result)\n",
    "        H_mean = np.mean(H, axis = 0)\n",
    "        h_diff = [h - H_mean for h in H]\n",
    "        qsum_H = 0\n",
    "        for w in range(M*2):\n",
    "          qsum_H += (h_diff[w])**2\n",
    "        # For current WeightHyphothesis, create an Correlation, this vector needs to be created for each time sample:\n",
    "        for time_sample in range(trace_len):\n",
    "            L = waves[:,time_sample]\n",
    "            l_diff = l_diff_list[time_sample]\n",
    "            sum_HL = 0\n",
    "            for w in range(M*2):\n",
    "              sum_HL += (h_diff[w])*(l_diff[w])\n",
    "            divider = (qsum_H**(1/2))*(qsum_L_list[time_sample]**(1/2))\n",
    "            corr = 0\n",
    "            if divider != 0:\n",
    "              corr = sum_HL / divider\n",
    "            corr_Tsamples.append(abs(corr))\n",
    "        corr_all_Tsamples.append(corr_Tsamples)\n",
    "    return corr_all_Tsamples\n",
    "def plot_mult(corr_list, type = \"norm\"):\n",
    "  t_corr_list = corr_list.transpose()\n",
    "  import matplotlib.pyplot as plt\n",
    "  image = plt.figure()\n",
    "  for corr in corr_list:\n",
    "    plt.plot(corr)\n",
    "  plt.show()\n",
    "  image.savefig(f'./figures/{epochs}_{type}_corr.png')\n",
    "\n",
    "\n",
    "def plot_one(array, type = \"norm\"):\n",
    "  import matplotlib.pyplot as plt\n",
    "  image = plt.figure()\n",
    "  plt.plot(array)\n",
    "  plt.show()\n",
    "  image.savefig(f'./figures/{epochs}_{type}_corr.png')\n",
    "\n",
    "def createDiffWave(waves, name):\n",
    "        diff_waves = []\n",
    "        square_waves = []\n",
    "        avg_wave = np.mean(waves,axis=0)\n",
    "        \n",
    "        for i in waves:\n",
    "            diff_waves.append(np.subtract(i,avg_wave))\n",
    "        for i in diff_waves:\n",
    "            square_wave = []\n",
    "            for ii in i:\n",
    "                square_wave.append(ii**2)\n",
    "            square_waves.append(square_wave)\n",
    "        \n",
    "        diff_avg = np.mean(diff_waves,axis=0)\n",
    "        var = np.mean(square_waves,axis=0)\n",
    "    \n",
    "        plot_one(np.array(waves[0]), type = f\"wave0_{name}\")\n",
    "        plot_one(np.array(avg_wave), type = f\"avg_wave_{name}\")\n",
    "        plot_one(np.array(diff_avg), type = f\"difference_wave_{name}\")\n",
    "        plot_one(np.array(var), type = f\"variation_{name}\")\n",
    "        return diff_avg, avg_wave, var, waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b113b25a-a8d7-42bd-a163-a06262b51c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(correlation_matrix: np.array, peak_range = 0.3, show_info=False, lastIndex = 0, map_2dgrMaxs = None, mountain_half_dist = 20, level = 5):\n",
    "    #FIND index of highest value for each column (correlation of time sample)\n",
    "    indx_ColmnMax = correlation_matrix.argmax(axis=0) #Return an vector of indexes of max values in each column of matrix\n",
    "    \n",
    "    #CREATE an array from previous finds\n",
    "    colmn_MaxVector = np.array([correlation_matrix[indx_ColmnMax[i]][i] for i in range(len(indx_ColmnMax))]) #Return a vector of max values for each column in matrix\n",
    "\n",
    "    #FIND GLOBAL MAX\n",
    "    indx_globMax = np.argmax(colmn_MaxVector)\n",
    "    val_globMax = colmn_MaxVector[indx_globMax]\n",
    "    vec_len = len(colmn_MaxVector)\n",
    "\n",
    "\n",
    "    if map_2dgrMaxs is None:\n",
    "\n",
    "        vals_locMaxVector0 = []\n",
    "        tmp_indices = []\n",
    "        for i in range(len(colmn_MaxVector)):\n",
    "            tmp_indices.append(i)\n",
    "            vals_locMaxVector0.append(0)\n",
    "        for i in range(level):\n",
    "            tmp_array = []\n",
    "            for indx in tmp_indices:\n",
    "                tmp_array.append(colmn_MaxVector[indx])\n",
    "            indices, props = scipy.signal.find_peaks(tmp_array)\n",
    "            for indx in range(len(indices)):\n",
    "                indices[indx] = tmp_indices[indices[indx]]\n",
    "            tmp_indices = indices\n",
    "        for indx in tmp_indices:\n",
    "            if val_globMax-peak_range <= colmn_MaxVector[indx]:\n",
    "                vals_locMaxVector0[indx] = colmn_MaxVector[indx]\n",
    "        \n",
    "        vals_locMaxVector1 = []\n",
    "        #FIND 1. local maxims and zero-out all values in tresshold range to global_correlation\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = colmn_MaxVector[indx]\n",
    "            val_toAppend = 0\n",
    "            if (value + peak_range) >= val_globMax and ((indx+1) < vec_len) and (value > colmn_MaxVector[indx+1]):\n",
    "                val_toAppend = value\n",
    "            vals_locMaxVector1.append(val_toAppend)\n",
    "        secret_corr = 0 #FINAL correlation\n",
    "        secret_colmn = 0 #Column/Time sample of Final correlation\n",
    "    \n",
    "        #FIND 2. local maxims\n",
    "        vals_locMaxVector2 = []\n",
    "        last_val = vals_locMaxVector1[0]\n",
    "        last_indx = 0\n",
    "        zero_counter = 0\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = vals_locMaxVector1[indx]\n",
    "            vals_locMaxVector2.append(0)\n",
    "            if value != 0:#Cross the desert, and on start of the next mountain, reminiscence about last mountain and save it to the memoar \n",
    "                if zero_counter > mountain_half_dist:\n",
    "                    vals_locMaxVector2[last_indx] = last_val\n",
    "                    #Reset\n",
    "                    last_val = 0\n",
    "                    last_indx = indx\n",
    "                else:\n",
    "                    if last_val < value:\n",
    "                        last_val = value\n",
    "                        last_indx = indx\n",
    "                zero_counter = 0\n",
    "            else:\n",
    "                zero_counter += 1\n",
    "        vals_locMaxVector2[last_indx] = last_val\n",
    "\n",
    "\n",
    "\n",
    "        #FIND 3. local maxims\n",
    "        vals_locMaxVector3 = []\n",
    "        last_val = vals_locMaxVector1[0]\n",
    "        last_indx = 0\n",
    "        zero_counter = 0\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = vals_locMaxVector1[indx]\n",
    "            vals_locMaxVector3.append(0)\n",
    "            if value > (last_val-peak_range):#Cross the desert, and on start of the next mountain, reminiscence about last mountain and save it to the memoar \n",
    "                if zero_counter > mountain_half_dist:\n",
    "                    vals_locMaxVector3[last_indx] = last_val\n",
    "                    #Reset\n",
    "                    last_val = 0\n",
    "                    last_indx = indx\n",
    "                else:\n",
    "                    if  last_val > value:\n",
    "                        vals_locMaxVector3[last_indx] = last_val\n",
    "                    last_val = value\n",
    "                    last_indx = indx\n",
    "                zero_counter = 0\n",
    "            else:\n",
    "                zero_counter += 1\n",
    "        vals_locMaxVector3[last_indx] = last_val\n",
    "    else:\n",
    "        vals_locMaxVector2 = map_2dgrMaxs\n",
    "    \n",
    "    secret_corr = 0 #FINAL correlation\n",
    "    secret_colmn = 0 #Column/Time sample of Final correlation\n",
    "    nextIndex = lastIndex\n",
    "    found = False\n",
    "    print(f\"In range {lastIndex} - {len(indx_ColmnMax)}\")\n",
    "    for indx in range(lastIndex, len(indx_ColmnMax)): #Find first local maxim in the peak_range from global maxim\n",
    "        value = vals_locMaxVector2[indx]\n",
    "        if value != 0:\n",
    "            if not found:\n",
    "                secret_corr = value\n",
    "                secret_colmn = indx\n",
    "                found = True\n",
    "                continue\n",
    "            nextIndex =  indx - round((indx - secret_colmn) / 2)\n",
    "            break\n",
    "    secret_val = indx_ColmnMax[secret_colmn]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if show_info and map_2dgrMaxs is None:    \n",
    "        #fig = plt.figure()\n",
    "        #plt.plot(indx_ColmnMax)\n",
    "        #plt.title('Indexes of max row in column')\n",
    "        \n",
    "        #fig = plt.figure()\n",
    "        #plt.plot(colmn_MaxVector)\n",
    "        #plt.title('Max correlation values grapth')\n",
    "\n",
    "\n",
    "\n",
    "        print(f\" Index of global max: {indx_globMax} and global_max_val: {val_globMax}\")\n",
    "\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(vals_locMaxVector0, color=\"green\")\n",
    "        plt.title(f'{level}th-level degree Local maxims graph')\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Secret Value\")\n",
    "        plt.show()\n",
    "\n",
    "        indx_localMax = []\n",
    "        for i in range(len(vals_locMaxVector0)):\n",
    "            val_toAppend = 0\n",
    "            if vals_locMaxVector0[i] > 0:\n",
    "                val_toAppend = indx_ColmnMax[i]\n",
    "            indx_localMax.append(val_toAppend)\n",
    "        print(f\"Local maxims: {[int(indx_ColmnMax[i]) for i in range(len(vals_locMaxVector0)) if vals_locMaxVector0[i] > 0]}\")\n",
    "        fig = plt.figure()\n",
    "        plt.plot(indx_localMax, color=\"green\")\n",
    "        plt.title(\"0. Local maxim's indexes graph\")\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Index\")\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.plot(vals_locMaxVector1, color=\"red\")\n",
    "        plt.title('1-th degree Local maxims graph')\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Secret Value\")\n",
    "        plt.show()\n",
    "        \n",
    "        indx_localMax = []\n",
    "        for i in range(len(vals_locMaxVector1)):\n",
    "            val_toAppend = 0\n",
    "            if vals_locMaxVector1[i] > 0:\n",
    "                val_toAppend = indx_ColmnMax[i]\n",
    "            indx_localMax.append(val_toAppend)\n",
    "        print(f\"Local maxims: {[int(indx_ColmnMax[i]) for i in range(len(vals_locMaxVector1)) if vals_locMaxVector1[i] > 0]}\")\n",
    "        fig = plt.figure()\n",
    "        plt.plot(indx_localMax, color=\"red\")\n",
    "        plt.title(\"1. Local maxim's indexes graph\")\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Index\")\n",
    "        plt.show()       \n",
    "\n",
    "\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(vals_locMaxVector2, color=\"blue\")\n",
    "        plt.title('2-th degee Local maxims graph')\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Secret Value\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        indx_localMax = []\n",
    "        for i in range(len(vals_locMaxVector2)):\n",
    "            val_toAppend = 0\n",
    "            if vals_locMaxVector2[i] > 0:\n",
    "                val_toAppend = indx_ColmnMax[i]\n",
    "            indx_localMax.append(val_toAppend)\n",
    "        print(f\"Local maxims: {[int(indx_ColmnMax[i]) for i in range(len(vals_locMaxVector2)) if vals_locMaxVector2[i] > 0]}\")\n",
    "        fig = plt.figure()\n",
    "        plt.plot(indx_localMax, color=\"blue\")\n",
    "        plt.title(\"2. Local maxim's indexes graph\")\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Index\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(vals_locMaxVector3, color=\"purple\")\n",
    "        plt.title('2-th-var degree Local maxims graph')\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Secret Value\")\n",
    "        plt.show()\n",
    "\n",
    "        indx_localMax = []\n",
    "        for i in range(len(vals_locMaxVector3)):\n",
    "            val_toAppend = 0\n",
    "            if vals_locMaxVector3[i] > 0:\n",
    "                val_toAppend = indx_ColmnMax[i]\n",
    "            indx_localMax.append(val_toAppend)\n",
    "        print(f\"Local maxims: {[int(indx_ColmnMax[i]) for i in range(len(vals_locMaxVector3)) if vals_locMaxVector3[i] > 0]}\")\n",
    "        fig = plt.figure()\n",
    "        plt.plot(indx_localMax, color=\"purple\")\n",
    "        plt.title(\"3. Local maxim's indexes graph\")\n",
    "        plt.xlabel(\"Time Sample\")\n",
    "        plt.ylabel(\"Index\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\" Found the soonest secret value is {secret_val}, at the time sample {secret_colmn}, with correlation {secret_corr = :.3f}\")\n",
    "    return secret_val, secret_colmn, secret_corr, vals_locMaxVector2, colmn_MaxVector, nextIndex, vals_locMaxVector2\n",
    "#results_directory = {}\n",
    "#secret_value, time_sample, correlation, localMax_vector = get_weight(np.array(ncorr_all), show_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d45b8f2-badb-4975-a84f-795886cf2508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ The Analyser succesfuly runned.\n"
     ]
    }
   ],
   "source": [
    "print(\"✔️ The Analyser succesfuly runned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d3733-f454-4217-aab3-afbe0a743c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
