{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ba739e-b1e3-4824-bdb0-a7514253e664",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e55c142-1a9f-4a66-b11d-f2c57bc0d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from typing import Callable as function\n",
    "class TextColor():\n",
    "        black = '\\033[30m'\n",
    "        red = '\\033[31m'\n",
    "        green = '\\033[32m'\n",
    "        orange = '\\033[33m'\n",
    "        blue = '\\033[34m'\n",
    "        purple = '\\033[35m'\n",
    "        cyan = '\\033[36m'\n",
    "        lightgrey = '\\033[37m'\n",
    "        darkgrey = '\\033[90m'\n",
    "        lightred = '\\033[91m'\n",
    "        lightgreen = '\\033[92m'\n",
    "        yellow = '\\033[93m'\n",
    "        lightblue = '\\033[94m'\n",
    "        pink = '\\033[95m'\n",
    "        lightcyan = '\\033[96m'\n",
    "        reset = '\\033[0m'\n",
    "save_rep = \"E:/DP_database/database\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b1373-695d-432d-a3c4-2bc131927b62",
   "metadata": {},
   "source": [
    "## Ulity Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbdc85-3377-4759-9ca6-543ddd06bd51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d551a-4b98-4a59-a891-fdce1adac885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Functions to get true value in case, in case that overflow was noted, in signed values\n",
    "#*\n",
    "def get_overflowed_val(val = 0, bnum = 8):\n",
    "    border = 2**(bnum-1)\n",
    "    if val >= border:\n",
    "        val = val % (border*2)\n",
    "        if val >= border:\n",
    "            val = -border + (val - border)\n",
    "    return val\n",
    "#*\n",
    "# Functions to get p_value, for current correlation vector\n",
    "#*\n",
    "def calc_p_val(corr: float, set_len: int, mode: int = 0) -> float:\n",
    "  t_stat = corr*( ((set_len-2) / (1 - corr**2))**0.5 )\n",
    "  if mode == 0:\n",
    "    df = set_len - 2  # degrees of freedom\n",
    "    p_value = 2 * stats.t.sf(abs(t_stat), df)  # Two-tailed p-value\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91036b9e-cc9b-432d-aef0-d19d8549d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Functions to Hamming weight, or otherwise number of 1 in binary representation vector of target number\n",
    "#*\n",
    "def hamming_weight(x, is_int = True):\n",
    "    if not is_int:\n",
    "        return np.count_nonzero(x == 1)\n",
    "    return bin(x).count(\"1\")\n",
    "#bnum = 8\n",
    "bnum = 16\n",
    "secret_range = 2**(bnum)\n",
    "hw = [hamming_weight(secret_value) for secret_value in range(secret_range)] \n",
    "#np.array([[1,2,3],[5,4,6]]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988670cd-f294-494b-bb3a-f58b78d8c10d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9782c874-4384-4451-bc38-8bfdd37136b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Visualize comparison between told true value graph, and all others\n",
    "#*\n",
    "def compTrueToAll_corrMatrix(corr_map, true_secret:int = 45, xlim:list[int]=None, ylim:list[int]=None, true_last=False, bnum = 8, saveName = None): \n",
    "    global save_rep\n",
    "    secret_corr = corr_map[true_secret]\n",
    "    corr_map = np.array(corr_map)\n",
    "    mask = np.ones(corr_map.shape[0], dtype=bool)\n",
    "    mask[true_secret] = False\n",
    "    all_false_corr = corr_map[mask, :]\n",
    "    indx_ColmnMax = all_false_corr.argmax(axis=0) #Return an vector of indexes of max values in each column of matrix\n",
    "    allFalseVector = np.array([all_false_corr[indx_ColmnMax[i]][i] for i in range(len(indx_ColmnMax))]) #Return a vector of max values for each column in matrix\n",
    "\n",
    "    image = plt.figure()\n",
    "    # Comparison to real correlation\n",
    "    if true_last:\n",
    "        plt.plot(allFalseVector, color='grey', label='all_not_true', linewidth=0.5)\n",
    "        plt.plot(secret_corr, color='red', label=f'secret_val_corr = {true_secret}', linewidth=0.5)\n",
    "    else:\n",
    "        plt.plot(secret_corr, color='red', label=f'secret_val_corr = {true_secret}', linewidth=0.5)\n",
    "        plt.plot(allFalseVector, color='grey', label='all_not_true', linewidth=0.5)\n",
    "    plt.legend(bbox_to_anchor=(0.75, 1.15), ncol=2)\n",
    "    plt.title(\"False_All (Grey) - True (Red)\")\n",
    "    plt.xlabel(\"Time Sample\")\n",
    "    plt.ylabel(\"Correlation\")\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    if saveName is not None:\n",
    "        image.savefig(f'{save_rep}/figures/{saveName}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b69daf9-1146-45f3-ac8d-269e838c523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Plot either one or many graphs into one output figure, with choosen parameters\n",
    "#*\n",
    "def plot_mult(corr_list, _type = \"norm\", mult=True, xlim:list[int]=None, ylim:list[int]=None,\n",
    "              graph_title=\"Multiple Correlation Traces\", ylabel=\"Correlation\", color=None, borders = None):\n",
    "    global save_rep\n",
    "    if not mult: #len(corr_list.shape) >  1:\n",
    "        corr_list = [corr_list]\n",
    "    image = plt.figure()\n",
    "    plt.title(graph_title)\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(ylabel)\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    for corr in corr_list:\n",
    "        if color is None:\n",
    "            plt.plot(corr)\n",
    "        else:\n",
    "            plt.plot(corr, color=color)\n",
    "    if borders is not None:\n",
    "        for i in borders:\n",
    "            plt.axvline(x = i, color = 'orange')\n",
    "    plt.show()\n",
    "    plt.close()  # Close the figure to free memory\n",
    "    os.makedirs('./figures', exist_ok=True)\n",
    "    image.savefig(f'{save_rep}/figures/{_type}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54792345-875e-48d6-80af-f7ed15026014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Dynamic SPA\n",
    "#*\n",
    "def createDiffWave(waves, name, showPlots=True):\n",
    "    waves = np.array(waves)\n",
    "    diff_waves = []\n",
    "    square_waves = []\n",
    "    avg_wave = np.mean(waves,axis=0)\n",
    "    \n",
    "    for i in waves:\n",
    "        diff_waves.append(np.subtract(i, avg_wave))\n",
    "    diff_waves = np.array(diff_waves)\n",
    "    diff_avg = np.mean(diff_waves,axis=0)\n",
    "    square_diff =  np.square(diff_waves)\n",
    "    dim1 = len(square_diff)\n",
    "    var = np.sum(square_diff, axis=0) / dim1\n",
    "    if showPlots:\n",
    "        plot_mult(np.array(waves[0]), _type = f\"wave0_{name}\", mult=False, graph_title=\"Waves[0]\", ylabel=\"Power\")\n",
    "        plot_mult(np.array(avg_wave), _type = f\"avg_wave_{name}\", mult=False, graph_title=\"Avg wave\", ylabel=\"Power\", color=\"green\")\n",
    "        plot_mult(np.array(diff_avg), _type = f\"difference_wave_{name}\", mult=False, graph_title=\"Difference wave\", ylabel=\"Power\", color=\"purple\")\n",
    "        plot_mult(np.array(var), _type = f\"variation_{name}\", mult=False, graph_title=\"Variation wave\", ylabel=\"Power\", color=\"orange\")\n",
    "        plot_mult(np.array(var**(0.5)), _type = f\"variation_{name}\", mult=False, graph_title=\"Standard deviation wave\", ylabel=\"Power\", color=\"brown\")\n",
    "    return diff_avg, avg_wave, var, waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a263125-33a6-4479-bdc8-7973362dbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extraction_method_info(vals_locMaxVector: list[int], indx_ColmnMax: list[int], method_name: str = f'xth-level degree', color: str = \"blue\"):\n",
    "    global save_rep\n",
    "    fig = plt.figure()\n",
    "    plt.plot(vals_locMaxVector, color=color)\n",
    "    plt.title(f'{method_name} Local maxims graph')\n",
    "    plt.xlabel(\"Time Sample\")\n",
    "    plt.ylabel(\"Secret Value\")\n",
    "    plt.show()\n",
    "    fig.savefig(f'{save_rep}/figures/get_weights/methods/{method_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    indx_localMax = []\n",
    "    for i in range(len(vals_locMaxVector)):\n",
    "        val_toAppend = 0\n",
    "        if vals_locMaxVector[i] > 0:\n",
    "            val_toAppend = indx_ColmnMax[i]\n",
    "        indx_localMax.append(val_toAppend)\n",
    "    local_maxims = [int(indx_ColmnMax[i]) for i in range(len(indx_ColmnMax)) if vals_locMaxVector[i] > 0]\n",
    "    uniques_set = [ x for i, x in enumerate(local_maxims) if x not in local_maxims[:i]]\n",
    "    print(f\"Number of uniques: {len(uniques_set)}\")\n",
    "    print(f\"Number of local maxims: {len(local_maxims)}\")\n",
    "    print(f\"Uniquess: {TextColor.pink}{uniques_set}{TextColor.reset}\")\n",
    "    print(f\"Local maxims: {TextColor.orange}{local_maxims}{TextColor.reset}\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(indx_localMax, color=color)\n",
    "    plt.title(f\"{method_name} indexes graph\")\n",
    "    plt.xlabel(\"Time Sample\")\n",
    "    plt.ylabel(\"Index\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a236e-ecb9-4548-ba4b-f6d7658f55e2",
   "metadata": {},
   "source": [
    "### Intermediate Values of multiplication, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951efcbe-3846-40b7-9413-7499fda1b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Return vector of resulting intermediate values\n",
    "#*\n",
    "def Abs_8bit_intermediateVal(secret_value: int, known_input: list[int]): # Abs_8-bit\n",
    "    H = np.uint32(known_input *  secret_value) % 256\n",
    "    return np.array(H)\n",
    "def Abs_32bit_intermediateVal(secret_value: int, known_input: list[int]):\n",
    "    H = np.uint32(known_input *  secret_value)\n",
    "    return np.array(H)\n",
    "def HW_8bit_intermediateVal(secret_value: int, known_input: list[int]):\n",
    "    global hw\n",
    "    H = [hw[np.uint32(known_input[i] *  secret_value) % 256] for i in range(len(known_input))]\n",
    "    return np.array(H)\n",
    "def HW_32bit_intermediateVal(secret_value: int, known_input: list[int]):\n",
    "    global hw\n",
    "    H = [hamming_weight(np.uint32(known_input[i] *  secret_value)) for i in range(len(known_input))]\n",
    "    return np.array(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e4190-74f3-4845-aae5-6f11872471d3",
   "metadata": {},
   "source": [
    "### CPA calc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be0b3c7-fec4-4271-b9e2-63a64a8d9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Agregate Functions: For calculation of correlation above, waves dataset, with hypotetical created traces based of known_input\n",
    "#*\n",
    "def general_CPA(known_input : list[int], hyp_leakage_cacl: function, waves = np.array([]),\n",
    "                ith_weight: int = 0, calc_p_value: bool = False, bnum:int=8): # Vanilla ANN CPA, for one time_sample a\n",
    "    # Verification of parameters:\n",
    "    n_traces = len(known_input)\n",
    "    trace_len = len(waves[0])\n",
    "\n",
    "    # Calculating statistics for traces in waves set\n",
    "    qsum_L_list = []\n",
    "    root_qsum_L_list = []\n",
    "    l_diff_list = []\n",
    "    for time_sample in range(trace_len):\n",
    "      # Calculation preparations: target sets extraction\n",
    "      L = waves[:,time_sample]\n",
    "      L_mean = np.mean(L)\n",
    "      # Calculation\n",
    "      l_diff = L - L_mean  # Vectorized\n",
    "      qsum_L = np.sum(np.square(l_diff))  # Sum of squared differences\n",
    "      # Tidy up\n",
    "      qsum_L_list.append(qsum_L)\n",
    "      root_qsum_L_list.append(qsum_L ** 0.5)\n",
    "      l_diff_list.append(l_diff)\n",
    "\n",
    "\n",
    "    # Preparational calculations, for case of quantization\n",
    "    corr_all_Tsamples = []\n",
    "    p_val_all_Tsamples = []\n",
    "    secret_range = 2**(bnum)\n",
    "    for secret_value in trange(secret_range, desc='Calculating Correlations for the Secret-Key: '): # For current WeightHypothesis do\n",
    "        #H = [calc_intermediate_val3(secret_value, known_input[j]) for j in range(n_traces)]\n",
    "        H = hyp_leakage_cacl(secret_value=secret_value, known_input=known_input)\n",
    "        H_mean = np.mean(H)\n",
    "        h_diff = H - H_mean\n",
    "        qsum_H = np.sum(np.square(h_diff))\n",
    "        root_q_sum_H = (qsum_H ** 0.5)\n",
    "\n",
    "        # For current WeightHypothesis, create an Correlation, this vector needs to be created for each time sample:\n",
    "        corr_Tsamples = []\n",
    "        for time_sample in range(trace_len):\n",
    "            # Calculation preparations: target sets extraction\n",
    "            l_diff = l_diff_list[time_sample]\n",
    "            sum_HL = np.sum(h_diff * l_diff)  # Dot product\n",
    "            # Calculation\n",
    "            divider = root_q_sum_H * root_qsum_L_list[time_sample]\n",
    "            corr = sum_HL / divider if divider != 0 else 0\n",
    "            # Tidy up\n",
    "            corr_Tsamples.append(corr)\n",
    "        corr_all_Tsamples.append(corr_Tsamples)\n",
    "        \n",
    "        p_val_Tsamples = []\n",
    "        if calc_p_value:\n",
    "            lenght = n_traces-2\n",
    "            for corr in corr_Tsamples:\n",
    "                t_stat = corr*( (lenght / (1 - corr**2))**0.5 )\n",
    "                df = n_traces - 2  # degrees of freedom\n",
    "                p_value = 2 * stats.t.sf(abs(t_stat), df)  # Two-tailed p-value\n",
    "                # Tidy up\n",
    "                p_val_Tsamples.append(p_value)\n",
    "            p_val_all_Tsamples.append(corr_Tsamples)\n",
    "    return np.array(corr_all_Tsamples), np.array(p_val_all_Tsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae765f9-9fad-441a-a09b-97a707fdec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Abs_8bit_ANN_CPA(known_input : list[int], waves = np.array([]), n_traces: int = None, trace_len: int = None, ith_weight: int = 0, calc_p_value: bool = False): # Vanilla ANN CPA, for one time_sample a\n",
    "    corr_all_Tsamples, p_val_all_Tsamples = general_CPA(known_input=known_input, hyp_leakage_cacl=Abs_8bit_intermediateVal,\n",
    "                                    waves=waves, ith_weight=ith_weight, calc_p_value=calc_p_value)\n",
    "    return corr_all_Tsamples, p_val_all_Tsamples\n",
    "\n",
    "def Abs_32bit_ANN_CPA(known_input : list[int], waves = np.array([]), n_traces: int = None, trace_len: int = None, ith_weight: int = 0, calc_p_value: bool = False): # Vanilla ANN CPA, for one time_sample a\n",
    "    corr_all_Tsamples, p_val_all_Tsamples = general_CPA(known_input=known_input, hyp_leakage_cacl=Abs_32bit_intermediateVal,\n",
    "                                    waves=waves, ith_weight=ith_weight, calc_p_value=calc_p_value)\n",
    "    return corr_all_Tsamples, p_val_all_Tsamples\n",
    "\n",
    "def HW_8bit_ANN_CPA(known_input : list[int], waves = np.array([]), n_traces: int = None, trace_len: int = None, ith_weight: int = 0, calc_p_value: bool = False): # Vanilla ANN CPA, for one time_sample a\n",
    "    corr_all_Tsamples, p_val_all_Tsamples = general_CPA(known_input=known_input, hyp_leakage_cacl=HW_8bit_intermediateVal,\n",
    "                                    waves=waves, ith_weight=ith_weight, calc_p_value=calc_p_value)\n",
    "    return corr_all_Tsamples, p_val_all_Tsamples\n",
    "\n",
    "def HW_32bit_ANN_CPA(known_input : list[int], waves = np.array([]), n_traces: int = None, trace_len: int = None, ith_weight: int = 0, calc_p_value: bool = False): # Vanilla ANN CPA, for one time_sample a\n",
    "    corr_all_Tsamples, p_val_all_Tsamples = general_CPA(known_input=known_input, hyp_leakage_cacl=HW_32bit_intermediateVal,\n",
    "                                    waves=waves, ith_weight=ith_weight, calc_p_value=calc_p_value)    \n",
    "    return corr_all_Tsamples, p_val_all_Tsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056b128e-74d6-417d-a876-3796b20c9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Agregate Functions: using opensource libraries, such as scipy, or np for calculating correlation,\n",
    "# as oposed to above functions using specific functions for correlation calculations\n",
    "#*\n",
    "def corr_2TraceMatrixes(traces: np.ndarray, inputs: list[int],\n",
    "                        trace_len: int = 24000, n_traces: int = 1000,\n",
    "                        xth_secret_val: int = 0, secret_range: int = 256,\n",
    "                        corr_func: function = np.corrcoef): # function can be also sc.pearsonr\n",
    "  #hw = [hamming_weight(secret_value) for secret_value in range(secret_range)]\n",
    "  leak_model = np.array([[calc_intermediate_val(secret_val, inputs[j]) for j in range(n_traces)] for secret_val in range(secret_range)])\n",
    "  corr_all = []\n",
    "  for i in trange(secret_range, desc='Calculating Correlations for secret key'):\n",
    "    corr_curr = []\n",
    "    to_corr_array = leak_model[i, :]\n",
    "    for j in range(trace_len):\n",
    "      corr_curr.append( corr_func(traces[:,j], to_corr_array))\n",
    "    corr_all.append(corr_curr)\n",
    "  return np.array(corr_all)\n",
    "from typing import Callable as function\n",
    "import scipy.stats as sc\n",
    "def sc_pearson_2TraceMatrixes(traces: np.ndarray, inputs: list[int],\n",
    "                        trace_len: int = 24000, n_traces: int = 1000,\n",
    "                        xth_secret_val: int = 0, secret_range: int = 256): # function can be also sc.pearsonr\n",
    "  #hw = [hamming_weight(secret_value) for secret_value in range(secret_range)]\n",
    "  leak_model = np.array([[calc_intermediate_val(secret_val, inputs[j]) for j in range(n_traces)] for secret_val in range(secret_range)])\n",
    "  corr_all = []\n",
    "  for i in trange(secret_range, desc='Calculating Correlations for secret key'):\n",
    "    corr_curr = []\n",
    "    #to_corr_array = np.array([leak_model[i,:] for n in range(trace_len)]).transpose()\n",
    "    #corr_all.append(scipy.stats.pearsonr(traces[:,0:trace_len], to_corr_array, axis=0))\n",
    "    for j in range(trace_len):\n",
    "      corr_curr.append(sc.pearsonr(traces[:,j], leak_model[i,:]))\n",
    "    #corr_all.append(sc.pearsonr(traces[:,0:trace_len], to_corr_array, axis=0))\n",
    "    corr_all.append(corr_curr)\n",
    "  return np.array(corr_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23df889-5d54-4d94-a3ce-1fe70c61eb23",
   "metadata": {},
   "source": [
    "### Extract weights from correlation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b113b25a-a8d7-42bd-a163-a06262b51c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*\n",
    "# Agregate Functions: for extracting relevant peaks of correlation matrix, with several fitting parameters\n",
    "#*\n",
    "def get_weight(correlation_matrix: np.array, min_treshold = 0.0, peak_range = 0.3, show_info=False, lastIndex = 0, map_2dgrMaxs = None, mountain_half_dist = 20, level = 5):\n",
    "    #FIND index of highest value for each column (correlation of time sample)\n",
    "    indx_ColmnMax = correlation_matrix.argmax(axis=0) #Return an vector of indexes of max values in each column of matrix\n",
    "    \n",
    "    #print(f\"Input Vector: {correlation_matrix[1]}\")\n",
    "\n",
    "    #CREATE an array from previous finds\n",
    "    colmn_MaxVector = np.array([correlation_matrix[indx_ColmnMax[i]][i] for i in range(len(indx_ColmnMax))]) #Return a vector of max values for each column in matrix\n",
    "    for i in range(len(colmn_MaxVector)):\n",
    "        if colmn_MaxVector[i] < min_treshold:\n",
    "            colmn_MaxVector[i] = 0\n",
    "    #FIND GLOBAL MAX\n",
    "    indx_globMax = np.argmax(colmn_MaxVector)\n",
    "    val_globMax = colmn_MaxVector[indx_globMax]\n",
    "    vec_len = len(colmn_MaxVector)\n",
    "    #print(f\"Max Vector: {colmn_MaxVector}\")\n",
    "\n",
    "\n",
    "    if map_2dgrMaxs is None:\n",
    "        print(f\"Peak range: {peak_range}\")\n",
    "        print(f\"{len([i for i in colmn_MaxVector if i != 0])}\")\n",
    "        vals_locMaxVector0 = []\n",
    "        tmp_indices = []\n",
    "        for i in range(len(colmn_MaxVector)):\n",
    "            tmp_indices.append(i)\n",
    "            vals_locMaxVector0.append(0)\n",
    "        for i in range(level):\n",
    "            tmp_array = []\n",
    "            for indx in tmp_indices:\n",
    "                tmp_array.append(colmn_MaxVector[indx])\n",
    "            indices, props = scipy.signal.find_peaks(tmp_array)\n",
    "            for indx in range(len(indices)):\n",
    "                indices[indx] = tmp_indices[indices[indx]]\n",
    "            tmp_indices = indices\n",
    "        for indx in range(len(colmn_MaxVector)):\n",
    "            if val_globMax-peak_range <= colmn_MaxVector[indx]:\n",
    "                vals_locMaxVector0[indx] = colmn_MaxVector[indx]\n",
    "        \n",
    "        vals_locMaxVector1 = []\n",
    "        #FIND 1. local maxims and zero-out all values in tresshold range to global_correlation\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = colmn_MaxVector[indx]\n",
    "            val_toAppend = 0\n",
    "            if (value + peak_range) >= val_globMax and ((indx+1) < vec_len) and (value > colmn_MaxVector[indx+1]):\n",
    "                val_toAppend = value\n",
    "            vals_locMaxVector1.append(val_toAppend)\n",
    "        secret_corr = 0 #FINAL correlation\n",
    "        secret_colmn = 0 #Column/Time sample of Final correlation\n",
    "    \n",
    "        #FIND 2. local maxims\n",
    "        vals_locMaxVector2 = []\n",
    "        last_val = vals_locMaxVector1[0]\n",
    "        last_indx = 0\n",
    "        zero_counter = 0\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = vals_locMaxVector1[indx]\n",
    "            vals_locMaxVector2.append(0)\n",
    "            if value != 0:#Cross the desert, and on start of the next mountain, reminiscence about last mountain and save it to the memoar \n",
    "                if zero_counter > mountain_half_dist:\n",
    "                    vals_locMaxVector2[last_indx] = last_val\n",
    "                    #Reset\n",
    "                    last_val = 0\n",
    "                    last_indx = indx\n",
    "                else:\n",
    "                    if last_val < value:\n",
    "                        last_val = value\n",
    "                        last_indx = indx\n",
    "                zero_counter = 0\n",
    "            else:\n",
    "                zero_counter += 1\n",
    "        vals_locMaxVector2[last_indx] = last_val\n",
    "\n",
    "\n",
    "\n",
    "        #FIND 3. local maxims\n",
    "        vals_locMaxVector3 = []\n",
    "        last_val = vals_locMaxVector1[0]\n",
    "        last_indx = 0\n",
    "        zero_counter = 0\n",
    "        for indx in range(vec_len): #shoud create vector with values which are local-maxims, other values are zeroed out\n",
    "            value = vals_locMaxVector1[indx]\n",
    "            vals_locMaxVector3.append(0)\n",
    "            if value > (last_val-(peak_range/2)):#Cross the desert, and on start of the next mountain, reminiscence about last mountain and save it to the memoar \n",
    "                if zero_counter > mountain_half_dist:\n",
    "                    vals_locMaxVector3[last_indx] = last_val\n",
    "                    #Reset\n",
    "                    last_val = 0\n",
    "                    last_indx = indx\n",
    "                else:\n",
    "                    if  last_val > value:\n",
    "                        vals_locMaxVector3[last_indx] = last_val\n",
    "                    last_val = value\n",
    "                    last_indx = indx\n",
    "                zero_counter = 0\n",
    "            else:\n",
    "                zero_counter += 1\n",
    "        vals_locMaxVector3[last_indx] = last_val\n",
    "\n",
    "\n",
    "        if show_info:    \n",
    "            print(f\" Index of global max: {indx_globMax} and global_max_val: {val_globMax}\")\n",
    "            show_extraction_method_info(vals_locMaxVector1, indx_ColmnMax, method_name = f'1th degree', color = \"red\")\n",
    "            show_extraction_method_info(vals_locMaxVector0, indx_ColmnMax, method_name = f'{level}-level', color = \"green\")\n",
    "            show_extraction_method_info(vals_locMaxVector2, indx_ColmnMax, method_name = f'2th-var degree', color = \"blue\")\n",
    "            show_extraction_method_info(vals_locMaxVector3, indx_ColmnMax, method_name = f'3th-var degree', color = \"purple\")\n",
    "    else:\n",
    "        vals_locMaxVector2 = map_2dgrMaxs\n",
    "    \n",
    "    secret_corr = 0 #FINAL correlation\n",
    "    secret_colmn = 0 #Column/Time sample of Final correlation\n",
    "    nextIndex = lastIndex\n",
    "    found = False\n",
    "    print(f\"In range {lastIndex} - {len(indx_ColmnMax)}\")\n",
    "    for indx in range(lastIndex, len(indx_ColmnMax)): #Find first local maxim in the peak_range from global maxim\n",
    "        value = vals_locMaxVector2[indx]\n",
    "        if value != 0:\n",
    "            if not found:\n",
    "                secret_corr = value\n",
    "                secret_colmn = indx\n",
    "                found = True\n",
    "                continue\n",
    "            nextIndex =  indx - round((indx - secret_colmn) / 2)\n",
    "            break\n",
    "    secret_val = indx_ColmnMax[secret_colmn]\n",
    "\n",
    "    \n",
    "    print(f\" Found the soonest secret value is {secret_val}, at the time sample {secret_colmn}, with correlation {secret_corr = :.3f}\")\n",
    "    return secret_val, secret_colmn, secret_corr, vals_locMaxVector2, colmn_MaxVector, nextIndex, vals_locMaxVector2\n",
    "#results_directory = {}\n",
    "#secret_value, time_sample, correlation, localMax_vector = get_weight(np.array(ncorr_all), show_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf8728-0782-49b9-ab2e-ae35abb3daab",
   "metadata": {},
   "source": [
    "## Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d45b8f2-badb-4975-a84f-795886cf2508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ The Analyser succesfuly runned.\n"
     ]
    }
   ],
   "source": [
    "print(\"✔️ The Analyser succesfuly runned.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
